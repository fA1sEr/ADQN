# This example is from Parr and Russell's paper on the SPOVA RL
# algorithm from IJCAI'95.

discount: 0.95
values: reward
states: 0 1 2 3 4 5 6
actions: 0 1 2
observations: 0 1 2 3 4 5

start include: 0

T : * : 0 : 1 0.5
T : * : 0 : 2 0.5

T : 0 : 1 : 3 1.0
T : 1 : 1 : 6 1.0
T : 2 : 1 : 5 1.0

T : 0 : 2 : 4 1.0
T : 1 : 2 : 5 1.0
T : 2 : 2 : 6 1.0

T : 0 : 3 : 1 1.0
T : 1 : 3 : 0 1.0
T : 2 : 3 : 0 1.0

T : 0 : 4 : 2 1.0
T : 1 : 4 : 0 1.0
T : 2 : 4 : 0 1.0

T : * : 5 : 0 1.0

T : * : 6 : 0 1.0

O : * : 0 : 0 1.0
O : * : 1 : 1 1.0
O : * : 2 : 1 1.0
O : * : 3 : 2 1.0
O : * : 4 : 3 1.0
O : * : 5 : 4 1.0
O : * : 6 : 5 1.0

# The paper has +1 and -1, but the SPOVA stuff requires 
# non-negative rewards
R: * : 5 : * : * 2.0
R: * : 6 : * : * 0.0